{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TensorFlow with GPU",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bisht1/linuxlover/blob/master/TensorFlow_with_GPU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "BlmQIFSLZDdc"
      },
      "cell_type": "markdown",
      "source": [
        "# Confirm TensorFlow can see the GPU\n",
        "\n",
        "Simply select \"GPU\" in the Accelerator drop-down in Notebook Settings (either through the Edit menu or the command palette at cmd/ctrl-shift-P)."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "3IEVK-KFxi5Z",
        "outputId": "0940e8b1-5283-4b2d-e3e6-8853f3deb804",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "QXRh0DPiZRyG"
      },
      "cell_type": "markdown",
      "source": [
        "# Observe TensorFlow speedup on GPU relative to CPU\n",
        "\n",
        "This example constructs a typical convolutional neural network layer over a\n",
        "random image and manually places the resulting ops on either the CPU or the GPU\n",
        "to compare execution speed."
      ]
    },
    {
      "metadata": {
        "id": "cToeYqzfeRZ0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ]
    },
    {
      "metadata": {
        "id": "4J3rqryJeUbV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 931
        },
        "outputId": "425b66e4-ef2b-42bb-c9f0-e9cfeac5ce9b"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf \n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot = True)\n",
        "\n",
        "n_nodes_hl1 = 500\n",
        "n_nodes_hl2 = 500\n",
        "n_nodes_hl3 = 500\n",
        "\n",
        "n_classes = 10\n",
        "batch_size = 100\n",
        "\n",
        "x = tf.placeholder('float',[None, 784])\n",
        "y = tf.placeholder('float')\n",
        "\n",
        "def neural_network_model(data):\n",
        "  \n",
        "  hidden_1_layer = {'weights':tf.Variable(tf.random_normal([784,n_nodes_hl1])),\n",
        "                   'biases':tf.Variable(tf.random_normal([n_nodes_hl1]))}\n",
        "  \n",
        "  hidden_2_layer = {'weights':tf.Variable(tf.random_normal([n_nodes_hl1, n_nodes_hl2])),\n",
        "                   'biases':tf.Variable(tf.random_normal([n_nodes_hl2]))}\n",
        "  \n",
        "  hidden_3_layer = {'weights':tf.Variable(tf.random_normal([n_nodes_hl2, n_nodes_hl3])),\n",
        "                   'biases':tf.Variable(tf.random_normal([n_nodes_hl3]))}\n",
        "  \n",
        "  output_layer = {'weights':tf.Variable(tf.random_normal([n_nodes_hl3,n_classes])),\n",
        "                   'biases':tf.Variable(tf.random_normal([n_classes]))}\n",
        "  \n",
        "  \n",
        "  l1 = tf.add(tf.matmul(data, hidden_1_layer['weights']), hidden_1_layer['biases'])\n",
        "  l1 = tf.nn.relu(l1)\n",
        "  \n",
        "  \n",
        "  l2 = tf.add(tf.matmul(l1, hidden_2_layer['weights']), hidden_2_layer['biases'])\n",
        "  l2 = tf.nn.relu(l2)\n",
        "  \n",
        "  l3 = tf.add(tf.matmul(l2, hidden_3_layer['weights']), hidden_3_layer['biases'])\n",
        "  l3 = tf.nn.relu(l3)\n",
        "  \n",
        "  output = tf.matmul(l3, output_layer['weights']) + output_layer['biases']\n",
        "  \n",
        "  return output\n",
        "\n",
        "\n",
        "def train_neural_network(x):\n",
        "  prediction = neural_network_model(x)\n",
        "  cost = tf.reduce_mean( tf.nn.softmax_cross_entropy_with_logits(prediction, y))\n",
        "  optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
        "  \n",
        "  hm_epochs = 10\n",
        "  \n",
        "  with tf.Sessions() as sess:\n",
        "    sess.run(tf.initialize_all_variables())\n",
        "    \n",
        "    for epoch in range(hm_epochs):\n",
        "        epoch_loss = 0\n",
        "        for _ in range(int(mnist.train.num_examples/batch_size)):\n",
        "            epoch_x, epoch_y = mnist.train.next_batch(batch_size)\n",
        "            _, c = sess.run([optimizer, cost], feed_dict = {x: x, y: y})\n",
        "            epoch_loss += c\n",
        "        print('Epoch', epoch, 'completed out of', hm_epochs, 'loss:',epoch_loss)\n",
        "        \n",
        "    correct = tf.equal(tf.argmax(prediction,1), tf.argmax(y,1))\n",
        "    \n",
        "    accuracy = tf.reduce.mean(tf.cast(correct,'float'))\n",
        "    \n",
        "    print('Accuracy:' ,accuracy.eval({x:mnist.test.images, y:mnist.test.labels}))\n",
        "    \n",
        "    \n",
        "train_neural_network(x)\n",
        "    \n",
        "  \n",
        "  \n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
            "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
            "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
            "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From <ipython-input-7-cccac20d3224>:47: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-cccac20d3224>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m \u001b[0mtrain_neural_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-cccac20d3224>\u001b[0m in \u001b[0;36mtrain_neural_network\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain_neural_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m   \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mneural_network_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m   \u001b[0mcost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax_cross_entropy_with_logits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m   \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdamOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    304\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m               instructions)\n\u001b[0;32m--> 306\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m     return tf_decorator.make_decorator(\n\u001b[1;32m    308\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36msoftmax_cross_entropy_with_logits\u001b[0;34m(_sentinel, labels, logits, dim, name)\u001b[0m\n\u001b[1;32m   1945\u001b[0m   \"\"\"\n\u001b[1;32m   1946\u001b[0m   _ensure_xent_args(\"softmax_cross_entropy_with_logits\", _sentinel, labels,\n\u001b[0;32m-> 1947\u001b[0;31m                     logits)\n\u001b[0m\u001b[1;32m   1948\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1949\u001b[0m   with ops.name_scope(name, \"softmax_cross_entropy_with_logits_sg\",\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36m_ensure_xent_args\u001b[0;34m(name, sentinel, labels, logits)\u001b[0m\n\u001b[1;32m   1757\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0msentinel\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1758\u001b[0m     raise ValueError(\"Only call `%s` with \"\n\u001b[0;32m-> 1759\u001b[0;31m                      \"named arguments (labels=..., logits=..., ...)\" % name)\n\u001b[0m\u001b[1;32m   1760\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlogits\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1761\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Both labels and logits must be provided.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Only call `softmax_cross_entropy_with_logits` with named arguments (labels=..., logits=..., ...)"
          ]
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "t9ALbbpmY9rm",
        "outputId": "c5ee74e3-f88b-4660-dcba-354d09fa5659",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import timeit\n",
        "\n",
        "# See https://www.tensorflow.org/tutorials/using_gpu#allowing_gpu_memory_growth\n",
        "config = tf.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "\n",
        "with tf.device('/cpu:0'):\n",
        "  random_image_cpu = tf.random_normal((100, 100, 100, 3))\n",
        "  net_cpu = tf.layers.conv2d(random_image_cpu, 32, 7)\n",
        "  net_cpu = tf.reduce_sum(net_cpu)\n",
        "\n",
        "with tf.device('/gpu:0'):\n",
        "  random_image_gpu = tf.random_normal((100, 100, 100, 3))\n",
        "  net_gpu = tf.layers.conv2d(random_image_gpu, 32, 7)\n",
        "  net_gpu = tf.reduce_sum(net_gpu)\n",
        "\n",
        "sess = tf.Session(config=config)\n",
        "\n",
        "# Test execution once to detect errors early.\n",
        "try:\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "except tf.errors.InvalidArgumentError:\n",
        "  print(\n",
        "      '\\n\\nThis error most likely means that this notebook is not '\n",
        "      'configured to use a GPU.  Change this in Notebook Settings via the '\n",
        "      'command palette (cmd/ctrl-shift-P) or the Edit menu.\\n\\n')\n",
        "  raise\n",
        "\n",
        "def cpu():\n",
        "  sess.run(net_cpu)\n",
        "  \n",
        "def gpu():\n",
        "  sess.run(net_gpu)\n",
        "  \n",
        "# Runs the op several times.\n",
        "print('Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images '\n",
        "      '(batch x height x width x channel). Sum of ten runs.')\n",
        "print('CPU (s):')\n",
        "cpu_time = timeit.timeit('cpu()', number=10, setup=\"from __main__ import cpu\")\n",
        "print(cpu_time)\n",
        "print('GPU (s):')\n",
        "gpu_time = timeit.timeit('gpu()', number=10, setup=\"from __main__ import gpu\")\n",
        "print(gpu_time)\n",
        "print('GPU speedup over CPU: {}x'.format(int(cpu_time/gpu_time)))\n",
        "\n",
        "sess.close()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images (batch x height x width x channel). Sum of ten runs.\n",
            "CPU (s):\n",
            "8.350230318000058\n",
            "GPU (s):\n",
            "0.1842791589999706\n",
            "GPU speedup over CPU: 45x\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}